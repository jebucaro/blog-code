import json
import logging
import time

from google import genai
from google.genai import types

from models import KnowledgeGraph
from settings import Settings

logger = logging.getLogger(__name__)

SYSTEM_PROMPT = """
    # Knowledge Graph Instructions for Gemini
    ## 1. Overview
    You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.
    Try to capture as much information from the text as possible without sacrificing accuracy. Do not add any information that is not explicitly mentioned in the text.
    - Nodes represent entities and concepts.
    - The aim is to achieve simplicity and clarity in the knowledge graph.

    ## 2. Node Fields
    The output Node must have two fields: `id` and `type`. DO NOT include a `label` field.

    ### ID (The Standardized Key)
    - **Formatting:** Node `id` MUST be generated by taking the human-readable text, converting it to **lowercase**, and replacing all spaces/special characters with **underscores (_)**.
    - **Crucial Rule for Numbers:** For numeric concepts (like "34 years old"), the ID must be prefixed with a meaningful string and use underscores.
    - **Example:** For "34 years old", the ID must be 'age_34'. For "Alex Johnson", the ID must be 'alex_johnson'.
    - **Constraints:** Never utilize standalone integers as node IDs.

    ### Type (The General Category)
    - **Formatting:** Node `type` must be basic, elementary, and **lowercase** (e.g., 'person', 'occupation', 'hobby').
    - **Consistency:** Always use basic types for node `type`. Avoid specific types like 'mathematician'.

    ## 3. Relationships
    - **Type Formatting:** Relationship `type` MUST be general, timeless, and **UPPERCASE** using **underscores (_)** as separators.
    - **Example:** Use 'WORKS_AS' instead of 'BECAME_PROFESSOR'.
    - **CRITICAL VALIDATION RULE:** Every relationship's `source_node_id` and `target_node_id` MUST reference a node `id` that exists in the nodes list you create.
    - **Before creating a relationship:** Verify that BOTH the source and target nodes have been extracted as nodes. If a node doesn't exist, you MUST create it first.
    - **Completeness:** If you reference an entity in a relationship, that entity MUST appear in the nodes list with a properly formatted `id`.

    ## 4. Coreference Resolution
    - **Consistency:** Ensure the generated **`id`** is consistent across all nodes and relationships.
    - **Example:** For "Alex Johnson" (referred to as "he"), the `id` should always be 'alex_johnson' in BOTH the nodes list AND all relationships.
    - **Apply ID formatting consistently:** When you reference an entity in a relationship, convert it to the same lowercase_underscore format you used for the node `id`.

    ## 5. Two-Pass Extraction Strategy
    To ensure completeness and consistency:
    1. **First Pass:** Extract all entities and concepts as nodes with properly formatted `id` and `type`.
    2. **Second Pass:** Create relationships, ensuring every `source_node_id` and `target_node_id` matches an `id` from your nodes list.
    3. **Validation:** Before finalizing, verify that every relationship references existing node IDs.

    ## 6. Strict Compliance
    Adhere to the rules strictly. Non-compliance will result in termination.
    - Every relationship MUST have valid source and target nodes
    - Node IDs must be consistent between nodes and relationships
    - Use the same ID formatting rules everywhere
"""


class GeminiExtractor:
    """Extract knowledge graphs from text using Google Gemini API."""

    def __init__(self, settings: Settings | None = None, api_key: str | None = None):
        """
        Initialize the GeminiExtractor

        Args:
            settings (Settings | None): Configuration object containing API key and model name.
            api_key (str | None): Direct API key string. If provided, it overrides config.
        """
        self.settings = settings or Settings()

        key_to_use = api_key or self.settings.gemini_api_key
        if not key_to_use:
            raise ValueError("Gemini API key must be provided via argument or Settings.gemini_api_key.")
        self.client = genai.Client(api_key=key_to_use)

        self.content_config = types.GenerateContentConfig(
            system_instruction=SYSTEM_PROMPT,
            response_mime_type="application/json",
            response_schema=KnowledgeGraph.model_json_schema(),
            # thinking_config=types.ThinkingConfig(thinking_budget=-1)
        )

        logger.info(f"Initialized Gemini extractor")

    def extract(self, text: str) -> KnowledgeGraph:
        """
        Extract a knowledge graph from the provided text.

        Args:
            text (str): The input text to extract the knowledge graph from.

        Returns:
            KnowledgeGraph: The extracted knowledge graph.
        """

        if not text or not text.strip():
            raise ValueError("Input text must be a non-empty string.")

        try:
            start_time = time.time()
            response = self.client.models.generate_content(
                model=self.settings.gemini_model,
                contents=text,
                config=self.content_config,
            )
            elapsed_time = time.time() - start_time
            logger.info(f"Gemini API responded in {elapsed_time:.2f}s")

            # Check if response was truncated
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                finish_reason = candidate.finish_reason

                if finish_reason and finish_reason != 'STOP':
                    logger.warning(f"Response may be incomplete. Finish reason: {finish_reason}")

            # Get text from response
            json_data = None
            try:
                json_data = response.text
            except Exception as e:
                logger.error(f"Error accessing response.text: {e}")
                # Try to access text directly from parts
                if hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                        if candidate.content.parts and hasattr(candidate.content.parts[0], 'text'):
                            json_data = candidate.content.parts[0].text

            if not json_data:
                raise ValueError("Empty response from Gemini API. The model may have hit token limits.")

            # Check if we got MAX_TOKENS after retrieving text
            if hasattr(response, 'candidates') and response.candidates:
                finish_reason = response.candidates[0].finish_reason
                if finish_reason == 'MAX_TOKENS':
                    logger.error(f"Response truncated at {len(json_data)} characters")
                    logger.error(f"Last 200 chars: {json_data[-200:]}")
                    raise ValueError(
                        f"Response exceeded maximum token limit ({len(json_data)} chars received but truncated). "
                        "The knowledge graph is too large for the current model. "
                        "Try: 1) Using shorter input text, "
                        "2) Increasing max_output_tokens in extractor.py, "
                        "3) Simplifying the extraction task"
                    )

            parsed_data = json.loads(json_data)

            # Log raw response for debugging (minified)
            logger.debug(f"Raw Gemini response: {json.dumps(parsed_data, separators=(',', ':'))}")

            knowledge_graph = KnowledgeGraph.model_validate(parsed_data)

            logger.info(
                f"Successfully extracted knowledge graph with {len(knowledge_graph.nodes)} nodes and {len(knowledge_graph.relationships)} relationships")
            return knowledge_graph
        except json.JSONDecodeError as e:
            logger.error(f"Failed to decode JSON response from Gemini: {e}")
            logger.error(f"Response length: {len(json_data)} characters")
            logger.error(f"Last 500 chars of response: {json_data[-500:]}")
            raise
        except Exception as e:
            logger.error(f"Validation error: {e}")
            raise

    def close(self):
        """Properly close the Gemini client to avoid cleanup errors."""
        try:
            if hasattr(self, 'client') and self.client:
                self.client.close()
        except Exception:
            pass  # Ignore errors during cleanup

    def __del__(self):
        """Destructor to ensure the client is closed."""
        self.close()
